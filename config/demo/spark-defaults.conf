#
# Licensed to the Apache Software Foundation (ASF) under one or more
# contributor license agreements.  See the NOTICE file distributed with
# this work for additional information regarding copyright ownership.
# The ASF licenses this file to You under the Apache License, Version 2.0
# (the "License"); you may not use this file except in compliance with
# the License.  You may obtain a copy of the License at
#
#    http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
#

# Default system properties included when running spark-submit.
# This is useful for setting default environmental settings.

# Example:
# spark.master                     spark://master:7077
# spark.eventLog.enabled           true
# spark.eventLog.dir               hdfs://namenode:8021/directory
# spark.serializer                 org.apache.spark.serializer.KryoSerializer
# spark.driver.memory              5g
# spark.executor.extraJavaOptions  -XX:+PrintGCDetails -Dkey=value -Dnumbers="one two three"


spark.default.parallelism   72
spark.sql.shuffle.partitions   72
spark.shuffle.sort.bypassMergeThreshold  72

spark.serializer    org.apache.spark.serializer.KryoSerializer

spark.streaming.concurrentJobs  1
spark.streaming.kafka.maxRatePerPartition   6000
spark.streaming.kafka.consumer.poll.ms      120000
spark.streaming.kafka.maxRetries     10

spark.task.cpus 1
spark.task.maxFailures 5
spark.cleaner.ttl   1800
spark.ui.killEnabled  false

spark.memory.offHeap.enabled  true
#10GB
spark.memory.offHeap.size  10737418240

spark.shuffle.io.numConnectionsPerPeer   24
spark.shuffle.io.retryWait               500ms
spark.shuffle.io.maxRetries              10
spark.reducer.maxSizeInFlight            32m
spark.shuffle.file.buffer                32k
spark.shuffle.spill.compress             true

spark.rpc.retry.wait 200ms
spark.scheduler.revive.interval 200ms
spark.network.timeout 120s

spark.locality.wait.process 300s
spark.locality.wait.node 0s
spark.locality.wait.rack 0s


spark.speculation               false
spark.speculation.interval      60s
spark.speculation.multiplier    3
spark.speculation.quantile      0.92

spark.kryo.unsafe   true
spark.kryoserializer.buffer.max  64m


spark.sql.inMemoryColumnarStorage.compressed  true
spark.sql.inMemoryColumnarStorage.batchSize   100000


#spark.rdd.compress     true
#spark.executor.extraJavaOptions  -XX:+UseConcMarkSweepGC

spark.executor.extraJavaOptions  -Djava.security.egd=file:/dev/./urandom
spark.driver.extraJavaOptions    -Djava.security.egd=file:/dev/./urandom

